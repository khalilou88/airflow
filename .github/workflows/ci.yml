name: Test Airflow Docker Compose

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  test-airflow-compose:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check system resources
        run: |
          echo "Checking system resources..."
          echo "Memory available:"
          docker run --rm "debian:bookworm-slim" bash -c 'numfmt --to iec $(echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE))))'
          echo "Disk space:"
          df -h
          echo "CPU info:"
          nproc

      - name: Create required directories and environment
        run: |
          # Create directories as per official documentation
          mkdir -p ./dags ./logs ./plugins ./config
          # Set AIRFLOW_UID for Linux as per official docs
          echo "AIRFLOW_UID=$(id -u)" > .env
          # Verify the .env file
          cat .env

      - name: Create a simple test DAG
        run: |
          cat > ./dags/test_dag.py << 'EOF'
          from datetime import datetime, timedelta
          from airflow import DAG
          from airflow.operators.bash import BashOperator

          default_args = {
              'owner': 'test',
              'depends_on_past': False,
              'start_date': datetime(2024, 1, 1),
              'email_on_failure': False,
              'email_on_retry': False,
              'retries': 1,
              'retry_delay': timedelta(minutes=5),
          }

          dag = DAG(
              'test_dag',
              default_args=default_args,
              description='A simple test DAG',
              schedule_interval=timedelta(days=1),
              catchup=False,
              tags=['test'],
          )

          test_task = BashOperator(
              task_id='test_task',
              bash_command='echo "Hello from Airflow test!"',
              dag=dag,
          )
          EOF

      - name: Initialize Airflow database
        run: |
          # Initialize the database as per official documentation
          echo "Running airflow-init to initialize database and create admin user..."
          docker compose up airflow-init

      - name: Start Airflow services
        run: |
          # Start all Airflow services as per official documentation
          echo "Starting Airflow services..."
          docker compose up -d

      - name: Wait for services to be healthy
        run: |
          echo "Waiting for services to be healthy..."

          # Function to check if container is healthy
          check_health() {
            local service=$1
            local timeout=${2:-300}
            local count=0

            while [ $count -lt $timeout ]; do
              # First check if the service exists and is running
              if ! docker compose ps "$service" --format json >/dev/null 2>&1; then
                echo "‚ö†Ô∏è  Service $service not found or not running"
                sleep 5
                count=$((count + 5))
                echo "Waiting for $service... ($count/$timeout seconds)"
                continue
              fi

              # Get the JSON output and debug it
              local json_output
              json_output=$(docker compose ps "$service" --format json 2>/dev/null)
              
              if [ -z "$json_output" ]; then
                echo "‚ö†Ô∏è  No output from docker compose ps for $service"
                sleep 5
                count=$((count + 5))
                echo "Waiting for $service... ($count/$timeout seconds)"
                continue
              fi

              # Check if it's an array or single object
              local health_status
              if echo "$json_output" | jq -e '. | type' | grep -q "array"; then
                # It's an array, use index 0
                health_status=$(echo "$json_output" | jq -r '.[0].Health // empty' 2>/dev/null)
              else
                # It's a single object
                health_status=$(echo "$json_output" | jq -r '.Health // empty' 2>/dev/null)
              fi

              # If Health field doesn't exist, check State instead
              if [ -z "$health_status" ]; then
                if echo "$json_output" | jq -e '. | type' | grep -q "array"; then
                  health_status=$(echo "$json_output" | jq -r '.[0].State // empty' 2>/dev/null)
                else
                  health_status=$(echo "$json_output" | jq -r '.State // empty' 2>/dev/null)
                fi
              fi

              # Check various healthy states
              if [[ "$health_status" == "healthy" ]] || [[ "$health_status" == "running" ]]; then
                echo "‚úÖ $service is healthy (status: $health_status)"
                return 0
              fi

              sleep 5
              count=$((count + 5))
              echo "Waiting for $service (status: $health_status)... ($count/$timeout seconds)"
            done

            echo "‚ùå $service failed to become healthy within $timeout seconds"
            return 1
          }

          # Alternative function using docker inspect (more reliable)
          check_health_inspect() {
            local service=$1
            local timeout=${2:-300}
            local count=0

            while [ $count -lt $timeout ]; do
              # Get container ID for the service
              local container_id
              container_id=$(docker compose ps -q "$service" 2>/dev/null)
              
              if [ -z "$container_id" ]; then
                echo "‚ö†Ô∏è  Service $service not found"
                sleep 5
                count=$((count + 5))
                echo "Waiting for $service... ($count/$timeout seconds)"
                continue
              fi

              # Check health using docker inspect
              local health_status
              health_status=$(docker inspect "$container_id" --format='{{.State.Health.Status}}' 2>/dev/null)
              
              # If no health check is defined, check if container is running
              if [ "$health_status" = "<no value>" ] || [ -z "$health_status" ]; then
                health_status=$(docker inspect "$container_id" --format='{{.State.Status}}' 2>/dev/null)
              fi

              if [[ "$health_status" == "healthy" ]] || [[ "$health_status" == "running" ]]; then
                echo "‚úÖ $service is healthy (status: $health_status)"
                return 0
              fi

              sleep 5
              count=$((count + 5))
              echo "Waiting for $service (status: $health_status)... ($count/$timeout seconds)"
            done

            echo "‚ùå $service failed to become healthy within $timeout seconds"
            return 1
          }

          # Function to debug docker compose output
          debug_service() {
            local service=$1
            echo "üîç Debugging $service:"
            echo "Raw docker compose ps output:"
            docker compose ps "$service" --format json | jq '.' 2>/dev/null || echo "Failed to parse JSON"
            echo "Container status via docker inspect:"
            local container_id
            container_id=$(docker compose ps -q "$service" 2>/dev/null)
            if [ -n "$container_id" ]; then
              docker inspect "$container_id" --format='Health: {{.State.Health.Status}}, Status: {{.State.Status}}' 2>/dev/null
            fi
            echo "---"
          }

          # Wait for core services to be healthy
          echo "Checking core services..."

          # Debug the first service to understand the JSON structure
          debug_service "postgres"

          # Use the more reliable inspect method
          check_health_inspect "postgres" 180
          check_health_inspect "redis" 180

          # Wait a bit for Airflow services to stabilize
          sleep 30

          # Check Airflow services
          echo "Checking Airflow services..."
          services=("airflow-apiserver" "airflow-scheduler" "airflow-dag-processor" "airflow-worker" "airflow-triggerer")
          for service in "${services[@]}"; do
            check_health_inspect "$service" 300
          done

          echo "üéâ All services are healthy!"

      - name: Verify container status
        run: |
          echo "=== Container Status ==="
          docker compose ps

          echo -e "\n=== Verifying all expected containers are running ==="
          expected_services=("postgres" "redis" "airflow-apiserver" "airflow-scheduler" "airflow-dag-processor" "airflow-worker" "airflow-triggerer")

          all_healthy=true

          for service in "${expected_services[@]}"; do
            # Simple approach: check if the service appears as "Up" and optionally "healthy" in docker compose ps
            if docker compose ps "$service" --format "table {{.Service}}\t{{.Status}}" | grep -E "(Up|healthy)" > /dev/null; then
              echo "‚úÖ $service is running"
            else
              echo "‚ùå $service is not running properly"
              echo "Status for $service:"
              docker compose ps "$service"
              echo "Recent logs for $service:"
              docker compose logs "$service" --tail=20
              all_healthy=false
            fi
          done

          if [ "$all_healthy" = true ]; then
            echo -e "\nüéâ All expected services are running!"
          else
            echo -e "\n‚ùå Some services are not healthy"
            exit 1
          fi

      - name: Test Airflow Web UI and API
        run: |
          echo "=== Testing Airflow Web UI ==="

          # Test basic connectivity
          echo "Testing basic connectivity to localhost:8080..."
          status_code=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 10 http://localhost:8080/ 2>/dev/null)
          echo "Root path returned HTTP status: $status_code"

          if [[ "$status_code" == "200" ]] || [[ "$status_code" == "302" ]]; then
              echo "‚úÖ Airflow web server is accessible"
          else
              echo "‚ùå Airflow web server is not accessible"
              echo "Checking container status..."
              docker compose ps airflow-apiserver
              echo "Checking recent logs..."
              docker compose logs airflow-apiserver --tail=10
              exit 1
          fi

          # Test what's actually available
          echo -e "\n=== Testing available endpoints ==="

          endpoints=(
              "/"
              "/login"
              "/admin/"
              "/api/v1/version"
              "/api/v2/version"
          )

          working_api=""

          for endpoint in "${endpoints[@]}"; do
              status=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 5 http://localhost:8080$endpoint 2>/dev/null)
              echo "  $endpoint: HTTP $status"
              
              # Check if this is a working API version endpoint
              if [[ "$endpoint" == "/api/v"* ]] && [[ "$status" == "200" || "$status" == "401" ]]; then
                  working_api=$(echo $endpoint | grep -o "v[0-9]")
                  echo "    ‚Üí Found working API version: $working_api"
              fi
          done

          # If we found a working API, test it with authentication
          if [ -n "$working_api" ]; then
              echo -e "\n=== Testing API with authentication ==="
              echo "Testing API $working_api with default credentials..."
              
              # Test version endpoint
              echo "Checking version..."
              version_response=$(curl -s -u airflow:airflow http://localhost:8080/api/$working_api/version 2>/dev/null)
              version_status=$(curl -s -o /dev/null -w "%{http_code}" -u airflow:airflow http://localhost:8080/api/$working_api/version 2>/dev/null)
              echo "Version endpoint status: $version_status"
              if [ "$version_status" = "200" ]; then
                  echo "Version response: $version_response"
              fi
              
              # Test DAGs endpoint
              echo "Checking DAGs..."
              dags_status=$(curl -s -o /dev/null -w "%{http_code}" -u airflow:airflow http://localhost:8080/api/$working_api/dags 2>/dev/null)
              echo "DAGs endpoint status: $dags_status"
              
              if [ "$dags_status" = "200" ]; then
                  dags_response=$(curl -s -u airflow:airflow http://localhost:8080/api/$working_api/dags 2>/dev/null)
                  if echo "$dags_response" | grep -q "test_dag"; then
                      echo "‚úÖ Test DAG found!"
                  else
                      echo "Available DAGs:"
                      echo "$dags_response" | jq -r '.dags[]?.dag_id // empty' 2>/dev/null | head -5 || echo "Could not parse DAG list"
                  fi
              fi
          else
              echo -e "\n‚ö†Ô∏è  No working API version found. This might be normal if authentication is required for all endpoints."
          fi

          echo -e "\n=== Summary ==="
          echo "Airflow web server is running and accessible on port 8080"
          echo "You can access the web UI at: http://localhost:8080"
          echo "Default credentials are typically: airflow / airflow"

      - name: Test CLI commands
        run: |
          echo "Testing Airflow CLI commands..."

          # Test airflow info command as per documentation
          docker compose run --rm airflow-worker airflow info

          # Test airflow version
          echo -e "\nTesting airflow version..."
          docker compose run --rm airflow-worker airflow version

          # List DAGs via CLI
          echo -e "\nListing DAGs via CLI..."
          docker compose run --rm airflow-worker airflow dags list

      - name: Test DAG execution
        run: |
          echo "=== Testing DAG execution ==="

          # First, make sure we have working credentials
          echo "1. Finding working credentials..."

          credentials=(
              "airflow:airflow"
              "admin:admin" 
              "admin:airflow"
          )

          working_creds=""
          for cred in "${credentials[@]}"; do
              status=$(curl -s -o /dev/null -w "%{http_code}" -u "$cred" http://localhost:8080/api/v2/version 2>/dev/null)
              if [ "$status" = "200" ]; then
                  working_creds="$cred"
                  echo "‚úÖ Working credentials: $cred"
                  break
              fi
          done

          # If no credentials work, try to create the default user
          if [ -z "$working_creds" ]; then
              echo "No working credentials found. Creating default airflow user..."
              
              create_result=$(docker compose exec -T airflow-apiserver airflow users create \
                  --role Admin \
                  --username airflow \
                  --email airflow@example.com \
                  --firstname Airflow \
                  --lastname Admin \
                  --password airflow 2>/dev/null || echo "FAILED")
              
              if echo "$create_result" | grep -q "successfully\|created"; then
                  echo "‚úÖ User created successfully"
                  working_creds="airflow:airflow"
                  # Give it a moment to propagate
                  sleep 5
              else
                  echo "‚ùå Failed to create user: $create_result"
                  exit 1
              fi
          fi

          # Verify we can access the API
          echo -e "\n2. Verifying API access..."
          api_status=$(curl -s -o /dev/null -w "%{http_code}" -u "$working_creds" http://localhost:8080/api/v2/version 2>/dev/null)
          if [ "$api_status" != "200" ]; then
              echo "‚ùå API access failed with status: $api_status"
              echo "API response:"
              curl -s -u "$working_creds" http://localhost:8080/api/v2/version 2>/dev/null || echo "No response"
              exit 1
          fi
          echo "‚úÖ API access verified"

          # Check if DAGs exist
          echo -e "\n3. Checking available DAGs..."
          dags_response=$(curl -s -u "$working_creds" http://localhost:8080/api/v2/dags 2>/dev/null)

          # Count available DAGs
          dag_count=$(echo "$dags_response" | jq -r '.total_entries // 0' 2>/dev/null)
          if [ "$dag_count" = "null" ] || [ -z "$dag_count" ]; then
              dag_count=0
          fi

          echo "Found $dag_count DAG(s)"

          if [ "$dag_count" -eq 0 ]; then
              echo "‚ùå No DAGs found. Creating a test DAG..."
              
              # Create a test DAG file
              cat > /tmp/test_dag.py << 'EOF'
          from datetime import datetime, timedelta
          from airflow import DAG
          from airflow.operators.bash import BashOperator
          from airflow.operators.python import PythonOperator

          def print_hello():
              print("Hello from Airflow!")
              return "Task completed successfully"

          default_args = {
              'owner': 'airflow',
              'depends_on_past': False,
              'start_date': datetime(2024, 1, 1),
              'email_on_failure': False,
              'email_on_retry': False,
              'retries': 1,
              'retry_delay': timedelta(minutes=5),
          }

          dag = DAG(
              'test_dag',
              default_args=default_args,
              description='A simple test DAG',
              schedule_interval=None,  # Manual trigger only
              catchup=False,
              tags=['test'],
          )

          # Task 1: Print date
          task1 = BashOperator(
              task_id='print_date',
              bash_command='date',
              dag=dag,
          )

          # Task 2: Python task
          task2 = PythonOperator(
              task_id='python_task',
              python_callable=print_hello,
              dag=dag,
          )

          # Task 3: Sleep and echo
          task3 = BashOperator(
              task_id='sleep_and_echo',
              bash_command='sleep 5 && echo "Test DAG completed successfully"',
              dag=dag,
          )

          # Set task dependencies
          task1 >> task2 >> task3
          EOF
              
              # Copy the DAG file to the Airflow DAGs directory
              echo "Copying test DAG to Airflow container..."
              docker compose exec -T airflow-apiserver mkdir -p /opt/airflow/dags
              docker compose cp /tmp/test_dag.py airflow-apiserver:/opt/airflow/dags/
              
              # Wait for DAG to be parsed
              echo "Waiting for DAG to be parsed (30 seconds)..."
              sleep 30
              
              # Check if the DAG is now available
              dags_response=$(curl -s -u "$working_creds" http://localhost:8080/api/v2/dags 2>/dev/null)
              dag_count=$(echo "$dags_response" | jq -r '.total_entries // 0' 2>/dev/null)
              
              if [ "$dag_count" -gt 0 ]; then
                  echo "‚úÖ Test DAG created successfully"
              else
                  echo "‚ùå Failed to create test DAG. Check Airflow logs:"
                  docker compose logs airflow-apiserver | tail -10
                  exit 1
              fi
          fi

          # Get available DAGs
          echo -e "\n4. Available DAGs:"
          available_dags=$(echo "$dags_response" | jq -r '.dags[]?.dag_id // empty' 2>/dev/null)
          if [ -z "$available_dags" ]; then
              echo "‚ùå Could not retrieve DAG list"
              exit 1
          fi

          echo "$available_dags"

          # Choose first available DAG or prefer test_dag
          dag_to_test=""
          if echo "$available_dags" | grep -q "test_dag"; then
              dag_to_test="test_dag"
              echo "Using test_dag for testing"
          else
              dag_to_test=$(echo "$available_dags" | head -1)
              echo "Using first available DAG: $dag_to_test"
          fi

          # Check if the DAG is paused and unpause it if needed
          echo -e "\n5. Checking DAG status..."
          dag_details=$(curl -s -u "$working_creds" "http://localhost:8080/api/v2/dags/$dag_to_test" 2>/dev/null)
          is_paused=$(echo "$dag_details" | jq -r '.is_paused // false' 2>/dev/null)

          if [ "$is_paused" = "true" ]; then
              echo "DAG is paused. Unpausing..."
              unpause_result=$(curl -s -X PATCH \
                  -u "$working_creds" \
                  -H "Content-Type: application/json" \
                  -d '{"is_paused": false}' \
                  "http://localhost:8080/api/v2/dags/$dag_to_test" 2>/dev/null)
              
              if echo "$unpause_result" | grep -q '"is_paused": false'; then
                  echo "‚úÖ DAG unpaused successfully"
              else
                  echo "‚ùå Failed to unpause DAG"
              fi
          else
              echo "‚úÖ DAG is active"
          fi

          # Trigger the DAG
          echo -e "\n6. Triggering DAG: $dag_to_test"
          trigger_response=$(curl -s -X POST \
              -u "$working_creds" \
              -H "Content-Type: application/json" \
              -d '{}' \
              "http://localhost:8080/api/v2/dags/$dag_to_test/dagRuns" 2>/dev/null)

          echo "Trigger response: $trigger_response"

          # Check if the trigger was successful
          dag_run_id=$(echo "$trigger_response" | jq -r '.dag_run_id // empty' 2>/dev/null)
          if [ -n "$dag_run_id" ] && [ "$dag_run_id" != "null" ] && [ "$dag_run_id" != "empty" ]; then
              echo "‚úÖ DAG triggered successfully with run ID: $dag_run_id"
              
              # Wait for execution
              echo -e "\n7. Monitoring DAG execution..."
              for i in {1..12}; do  # Check for up to 60 seconds
                  sleep 5
                  echo "Checking status... (${i}/12)"
                  
                  run_response=$(curl -s -u "$working_creds" \
                      "http://localhost:8080/api/v2/dags/$dag_to_test/dagRuns/$dag_run_id" 2>/dev/null)
                  
                  run_status=$(echo "$run_response" | jq -r '.state // empty' 2>/dev/null)
                  
                  case "$run_status" in
                      "success")
                          echo "üéâ DAG execution completed successfully!"
                          break
                          ;;
                      "failed")
                          echo "‚ùå DAG execution failed"
                          break
                          ;;
                      "running")
                          echo "‚è≥ DAG is still running..."
                          ;;
                      *)
                          echo "‚ÑπÔ∏è DAG status: $run_status"
                          ;;
                  esac
              done
              
              # Final status check
              echo -e "\n8. Final status report..."
              run_response=$(curl -s -u "$working_creds" \
                  "http://localhost:8080/api/v2/dags/$dag_to_test/dagRuns/$dag_run_id" 2>/dev/null)
              
              run_status=$(echo "$run_response" | jq -r '.state // empty' 2>/dev/null)
              start_date=$(echo "$run_response" | jq -r '.start_date // empty' 2>/dev/null)
              end_date=$(echo "$run_response" | jq -r '.end_date // empty' 2>/dev/null)
              
              echo "DAG run status: $run_status"
              echo "Start date: $start_date"
              echo "End date: $end_date"
              
              # Get task instances status
              echo -e "\nTask status:"
              tasks_response=$(curl -s -u "$working_creds" \
                  "http://localhost:8080/api/v2/dags/$dag_to_test/dagRuns/$dag_run_id/taskInstances" 2>/dev/null)
              
              if echo "$tasks_response" | jq -e '.task_instances[]?' > /dev/null 2>&1; then
                  echo "$tasks_response" | jq -r '.task_instances[] | "  \(.task_id): \(.state)"' 2>/dev/null
              else
                  echo "  No task information available"
              fi
              
          else
              echo "‚ùå Failed to trigger DAG"
              echo "Response details: $trigger_response"
              
              # Check for common issues
              if echo "$trigger_response" | grep -q "Not authenticated\|Unauthorized"; then
                  echo "üîç Authentication issue detected"
              elif echo "$trigger_response" | grep -q "DAG.*not found"; then
                  echo "üîç DAG not found issue"
              elif echo "$trigger_response" | grep -q "paused"; then
                  echo "üîç DAG may be paused"
              fi
              exit 1
          fi

          echo -e "\n‚úÖ DAG execution test completed!"

      - name: Clean up
        if: always()
        run: |
          echo "Cleaning up Docker Compose environment..."
          # Stop and remove containers, networks, and volumes as per official documentation
          docker compose down --volumes --remove-orphans

          # Optional: Remove images to free up space
          # docker compose down --volumes --remove-orphans --rmi all

      - name: Show logs on failure
        if: failure()
        run: |
          echo "=== Docker Compose Services Status ==="
          docker compose ps

          echo -e "\n=== System Resources ==="
          df -h
          docker system df

          echo -e "\n=== Airflow Init Logs ==="
          docker compose logs airflow-init || echo "airflow-init container not found"

          echo -e "\n=== Airflow API Server Logs ==="
          docker compose logs airflow-apiserver --tail=50

          echo -e "\n=== Airflow Scheduler Logs ==="
          docker compose logs airflow-scheduler --tail=50

          echo -e "\n=== Airflow DAG Processor Logs ==="
          docker compose logs airflow-dag-processor --tail=50

          echo -e "\n=== Airflow Worker Logs ==="
          docker compose logs airflow-worker --tail=50

          echo -e "\n=== Airflow Triggerer Logs ==="
          docker compose logs airflow-triggerer --tail=50

          echo -e "\n=== Postgres Logs ==="
          docker compose logs postgres --tail=30

          echo -e "\n=== Redis Logs ==="
          docker compose logs redis --tail=30
